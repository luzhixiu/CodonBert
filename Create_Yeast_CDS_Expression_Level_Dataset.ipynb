{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e858ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9476b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86740e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected id Type: locus_tag\n",
      "There are 0 entries NOT found out of 5990\n",
      "5990 distinct record in 5990 entries\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# setting path\n",
    "sys.path.append('./CUB_Code/')\n",
    "import findSequenceById as FSB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def createBinaryList(lst):\n",
    "    binaryList=[]\n",
    "    med=np.median(lst)\n",
    "    for x in lst:\n",
    "        if x>=med:\n",
    "            binaryList.append(1)\n",
    "        else:\n",
    "            binaryList.append(0)\n",
    "    return binaryList\n",
    "\n",
    "\n",
    "def convertListToLabels(lst,n_label=3,distri=[0.2,0.6,0.2],labels=[0,1,2]):\n",
    "    sortedLst=lst.sorted()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "geneDict=FSB.findSequenceByID(\"./Data/s288c.fasta\")\n",
    "df1=pd.DataFrame(geneDict.items(),columns=[\"GeneName\",\"Sequence\"])\n",
    "df2=pd.read_csv(\"./S288C_Expression/EmpiricalExp/exp.csv\")\n",
    "df=pd.merge(df1,df2,on=\"GeneName\")\n",
    "binList=createBinaryList(df[\"EXP\"])\n",
    "df[\"Label\"]=binList\n",
    "df.to_csv(\"Full_S288C.datatable.csv\")\n",
    "\n",
    "\n",
    "#Create a samll table where middle exp tiers are removed and provide strong exp signals (higher confidence on labels)\n",
    "topSelectionRatio=1\n",
    "botSelectionRatio=1\n",
    "topSize=int(topSelectionRatio*len(df))\n",
    "botSize=int(botSelectionRatio*len(df))\n",
    "\n",
    "lowIndex=botSize\n",
    "highIndex=len(df)-topSize\n",
    "\n",
    "#sort the table by exp, and remove the \"middle\" hunk\n",
    "df=df.sort_values(\"EXP\")\n",
    "df=df.drop(df.index[lowIndex:highIndex])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a2199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84e5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f94a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af03202c",
   "metadata": {},
   "source": [
    "After loading the data, the next step is to convert the raw coding sequences to text sentences compsed of codon usage ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bb4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac75ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, './CUB_Code')\n",
    "import CodonLibraries as CL\n",
    "\n",
    "seqList=df[\"Sequence\"]\n",
    "sentenceList=[]\n",
    "for seq in seqList:\n",
    "    codonList = CL.loadSequence(seq)\n",
    "    sentence=\"\"\n",
    "    for codon in codonList:\n",
    "        sentence+=codon+\" \"\n",
    "    sentenceList.append(sentence[:-1])#this removes the extra redundant space in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea9956",
   "metadata": {},
   "source": [
    "Now we have converted the sequence to codonLists, then concated them into string sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad09bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAC TAT TTG GAA ACA CAG TTA AAT AAA AAG CAA AAA CAG ATA CAG GAA TAC GAA AGT ATG AAT GGC AAC CTG ATA AAG ATG TTT GAG CAA TTG TCT AAA GAA AAG AAA AAT GAT GAG ACA CCA AAA AAA ATT TCC TCG ACG TAC ATT AAA GAG TTA AAG GAG TAC AAC GAA TTG AGA GAT GCC GGT TTA AGG TTG GCC CAA ATA ATT GCT GAT GAA AAG CAA TGC AAA ATT AAG GAT GTT TTT GAA GAG ATC GGT TAT TCA ATG AAG GAC']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceList[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939a3a9",
   "metadata": {},
   "source": [
    "The next step is to get the genome wide codon usage and generate codon ranks, which will used to replace the codon strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c67da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findSequenceById as FSBID\n",
    "from CAI import RSCU\n",
    "import scipy.stats as ss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process(seqList,genomeFile,tag=\"\"):\n",
    "    geneDict=FSBID.findSequenceByID(genomeFile)\n",
    "    keyList=[]\n",
    "    rscu=RSCU(seqList)\n",
    "    rscu_rank=convertRSCUtoRanks(rscu)\n",
    "    sentenceList = []\n",
    "    for seq in seqList:\n",
    "        codonList=CL.loadSequence(seq)\n",
    "        #remove the first and last five codons:\n",
    "        codonList = codonList[5:]\n",
    "        codonList = codonList[:-5]\n",
    "        try:\n",
    "            codonRankList=[rscu_rank[codon] for codon in codonList]\n",
    "            sentence=\"\"\n",
    "            for rank in codonRankList:\n",
    "                sentence+=str(rank)+\" \"\n",
    "            sentenceList.append(sentence[:-1])\n",
    "        except :\n",
    "            print(\"one error on \",seq)\n",
    "    \n",
    "    return sentenceList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convertRSCUtoRanks(rscu):\n",
    "    synonymousCodons = {\n",
    "        'CYS': ['TGT', 'TGC'],\n",
    "        'ASP': ['GAT', 'GAC'],\n",
    "        'SER': ['TCT', 'TCG', 'TCA', 'TCC', 'AGC', 'AGT'],\n",
    "        'GLN': ['CAA', 'CAG'],\n",
    "        'MET': ['ATG'],\n",
    "        'ASN': ['AAC', 'AAT'],\n",
    "        'PRO': ['CCT', 'CCG', 'CCA', 'CCC'],\n",
    "        'LYS': ['AAG', 'AAA'],\n",
    "        'THR': ['ACC', 'ACA', 'ACG', 'ACT'],\n",
    "        'PHE': ['TTT', 'TTC'],\n",
    "        'ALA': ['GCA', 'GCC', 'GCG', 'GCT'],\n",
    "        'GLY': ['GGT', 'GGG', 'GGA', 'GGC'],\n",
    "        'ILE': ['ATC', 'ATA', 'ATT'],\n",
    "        'LEU': ['TTA', 'TTG', 'CTC', 'CTT', 'CTG', 'CTA'],\n",
    "        'HIS': ['CAT', 'CAC'],\n",
    "        'ARG': ['CGA', 'CGC', 'CGG', 'CGT', 'AGG', 'AGA'],\n",
    "        'TRP': ['TGG'],\n",
    "        'VAL': ['GTA', 'GTC', 'GTG', 'GTT'],\n",
    "        'GLU': ['GAG', 'GAA'],\n",
    "        'TYR': ['TAT', 'TAC']}#'CYS': ['TGT', 'TGC']\n",
    "    rscu_rank=dict()\n",
    "    for aa in synonymousCodons:\n",
    "        codonList=synonymousCodons[aa]\n",
    "        rscuList=[rscu[codon] for codon in codonList]\n",
    "        rankList=ss.rankdata([-1*x for x in rscuList])\n",
    "        for codon,rank in zip(codonList,rankList):\n",
    "            rscu_rank[codon]=int(rank)\n",
    "    return rscu_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f52027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568\n",
      "1941    ATGAACTATTTGGAAACACAGTTAAATAAAAAGCAAAAACAGATAC...\n",
      "4329    ATGCACAATCAGGAAGAGTGGCTAGACAAGGACAAAACTTTGGTGA...\n",
      "1496    ATGGGAGCTGGCACTCTTTTAAATGGATTAGAAAAGGAAAACTTTC...\n",
      "2025    ATGAATCAAGGTTACACACAGCTTTCCGCACCGGAACTGAAGGAGA...\n",
      "4202    ATGCTTTTCGCTAGATTAGTGCTGCTGTTGGTGTATTTGGCACCAG...\n",
      "3056    ATGGATTGCCCCTCAAACGTTGTGTTATTGTTGCTGCAATTAGTTT...\n",
      "2788    ATGAACATTAAGACTTTGTGTCATCCAGAATATAAAAGAATCTCCG...\n",
      "1425    ATGAGTTTCCTAAGCATTTTTACTTTTTTCAGCGTCCTTATTTCTG...\n",
      "3323    ATGTACGAGTACTGCTCAGTTGTAATAAAGAAATACTCCAAGTATA...\n",
      "1492    ATGGTGACTGGTGAAGAAAATGTGTATCTAAAGTCAAGCTTATCCA...\n",
      "Name: Sequence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "genomeFile=\"./Data/s288c.fasta\"\n",
    "print(len(seqList))\n",
    "print(seqList[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fd80a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected id Type: locus_tag\n",
      "There are 0 entries NOT found out of 5990\n",
      "5990 distinct record in 5990 entries\n"
     ]
    }
   ],
   "source": [
    "sentenceList=process(list(seqList),genomeFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126109d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568\n",
      "['2 2 1 1 2 1 1 2 2 2 1 2 1 3 1 1 3 2 5 2 2 1 1 2 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 4 6 4 2 1 1 2 2 2 2 2 2 1 1 1 1 3 1 2 2 1 3 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 3 1']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentenceList))\n",
    "print(sentenceList[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbf0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3298dceb",
   "metadata": {},
   "source": [
    "We now have the intermediate sentence structure composed of characters including all codon rnaks, this can also be used for training the model and tokenizer, but we will apply one more operation on this file, composing single codon ranks into words of size k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbce831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLineToWords(line,n):\n",
    "    line= line.replace(' ','')\n",
    "    wordList=[]\n",
    "    for i in range(0,len(line)-n,n):\n",
    "        wordList.append(line[i:i+n])\n",
    "    sentence=\" \".join(wordList)\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90d452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231f6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1 #k specifies the wordsize, aka number of codon ranks in a word, or understood as size of codon windows\n",
    "wordSentenceList=[]\n",
    "for sentence in sentenceList:\n",
    "    wordSentence=convertLineToWords(sentence,k)\n",
    "    wordSentenceList.append(wordSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056c22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39db9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelList=df[\"Label\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b956d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"WordSentence\"]=wordSentenceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c963728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4567\n"
     ]
    }
   ],
   "source": [
    "df[\"SentenceLength\"]=[len(x) for x in df[\"WordSentence\"]]\n",
    "df=df[df['SentenceLength'] >= 2]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2efca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub=df[[\"WordSentence\",\"Label\"]].copy()\n",
    "df_sub=df_sub.rename(columns={\"WordSentence\": \"text\", \"Label\": \"label\"})\n",
    "OutputName=\"\"\n",
    "OutputName+=\"./Data/expressionPrediction_S288C\"\n",
    "OutputName+=\"_top_\"+str(topSelectionRatio)\n",
    "OutputName+=\"_bot_\"+str(botSelectionRatio)\n",
    "OutputName+=\"_k_\"+str(k)\n",
    "OutputName+=\".csv\"\n",
    "df_sub.to_csv(OutputName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd0b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df_sub)\n",
    "df.to_csv(\"FullTable_k1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6ff1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb0d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e29e178",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a96c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
