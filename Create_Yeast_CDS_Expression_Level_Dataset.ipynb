{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e858ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9476b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24a2199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   GeneName                                           Sequence  \\\n",
      "0        1941  YHR079C-A  ATGAACTATTTGGAAACACAGTTAAATAAAAAGCAAAAACAGATAC...   \n",
      "1        4329    YPL121C  ATGCACAATCAGGAAGAGTGGCTAGACAAGGACAAAACTTTGGTGA...   \n",
      "2        1496    YGL170C  ATGGGAGCTGGCACTCTTTTAAATGGATTAGAAAAGGAAAACTTTC...   \n",
      "\n",
      "         EXP  Label  \n",
      "0  59.599320      0  \n",
      "1  59.995476      0  \n",
      "2  62.303841      0  \n"
     ]
    }
   ],
   "source": [
    "inputFile=\"./S288C_Expression/EmpiricalExp/S288C.datatable_0.3Top_0.3Bot.csv\"\n",
    "df=pd.read_csv(inputFile)\n",
    "print(df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af03202c",
   "metadata": {},
   "source": [
    "After loading the data, the next step is to convert the raw coding sequences to text sentences compsed of codon usage ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bb4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac75ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, './CUB_Code')\n",
    "import CodonLibraries as CL\n",
    "\n",
    "seqList=df[\"Sequence\"]\n",
    "sentenceList=[]\n",
    "for seq in seqList:\n",
    "    codonList = CL.loadSequence(seq)\n",
    "    sentence=\"\"\n",
    "    for codon in codonList:\n",
    "        sentence+=codon+\" \"\n",
    "    sentenceList.append(sentence[:-1])#this removes the extra redundant space in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea9956",
   "metadata": {},
   "source": [
    "Now we have converted the sequence to codonLists, then concated them into string sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad09bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAC TAT TTG GAA ACA CAG TTA AAT AAA AAG CAA AAA CAG ATA CAG GAA TAC GAA AGT ATG AAT GGC AAC CTG ATA AAG ATG TTT GAG CAA TTG TCT AAA GAA AAG AAA AAT GAT GAG ACA CCA AAA AAA ATT TCC TCG ACG TAC ATT AAA GAG TTA AAG GAG TAC AAC GAA TTG AGA GAT GCC GGT TTA AGG TTG GCC CAA ATA ATT GCT GAT GAA AAG CAA TGC AAA ATT AAG GAT GTT TTT GAA GAG ATC GGT TAT TCA ATG AAG GAC']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceList[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939a3a9",
   "metadata": {},
   "source": [
    "The next step is to get the genome wide codon usage and generate codon ranks, which will used to replace the codon strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c67da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findSequenceById as FSBID\n",
    "from CAI import RSCU\n",
    "import scipy.stats as ss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process(seqList,genomeFile,tag=\"\"):\n",
    "    geneDict=FSBID.findSequenceByID(genomeFile)\n",
    "    keyList=[]\n",
    "    rscu=RSCU(seqList)\n",
    "    rscu_rank=convertRSCUtoRanks(rscu)\n",
    "    sentenceList = []\n",
    "    for seq in seqList:\n",
    "        codonList=CL.loadSequence(seq)\n",
    "        #remove the first and last five codons:\n",
    "        codonList = codonList[5:]\n",
    "        codonList = codonList[:-5]\n",
    "        try:\n",
    "            codonRankList=[rscu_rank[codon] for codon in codonList]\n",
    "            sentence=\"\"\n",
    "            for rank in codonRankList:\n",
    "                sentence+=str(rank)+\" \"\n",
    "            sentenceList.append(sentence[:-1])\n",
    "        except :\n",
    "            print(\"one error on \",seq)\n",
    "    \n",
    "    return sentenceList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convertRSCUtoRanks(rscu):\n",
    "    synonymousCodons = {\n",
    "        'CYS': ['TGT', 'TGC'],\n",
    "        'ASP': ['GAT', 'GAC'],\n",
    "        'SER': ['TCT', 'TCG', 'TCA', 'TCC', 'AGC', 'AGT'],\n",
    "        'GLN': ['CAA', 'CAG'],\n",
    "        'MET': ['ATG'],\n",
    "        'ASN': ['AAC', 'AAT'],\n",
    "        'PRO': ['CCT', 'CCG', 'CCA', 'CCC'],\n",
    "        'LYS': ['AAG', 'AAA'],\n",
    "        'THR': ['ACC', 'ACA', 'ACG', 'ACT'],\n",
    "        'PHE': ['TTT', 'TTC'],\n",
    "        'ALA': ['GCA', 'GCC', 'GCG', 'GCT'],\n",
    "        'GLY': ['GGT', 'GGG', 'GGA', 'GGC'],\n",
    "        'ILE': ['ATC', 'ATA', 'ATT'],\n",
    "        'LEU': ['TTA', 'TTG', 'CTC', 'CTT', 'CTG', 'CTA'],\n",
    "        'HIS': ['CAT', 'CAC'],\n",
    "        'ARG': ['CGA', 'CGC', 'CGG', 'CGT', 'AGG', 'AGA'],\n",
    "        'TRP': ['TGG'],\n",
    "        'VAL': ['GTA', 'GTC', 'GTG', 'GTT'],\n",
    "        'GLU': ['GAG', 'GAA'],\n",
    "        'TYR': ['TAT', 'TAC']}#'CYS': ['TGT', 'TGC']\n",
    "    rscu_rank=dict()\n",
    "    for aa in synonymousCodons:\n",
    "        codonList=synonymousCodons[aa]\n",
    "        rscuList=[rscu[codon] for codon in codonList]\n",
    "        rankList=ss.rankdata([-1*x for x in rscuList])\n",
    "        for codon,rank in zip(codonList,rankList):\n",
    "            rscu_rank[codon]=int(rank)\n",
    "    return rscu_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f52027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740\n",
      "0    ATGAACTATTTGGAAACACAGTTAAATAAAAAGCAAAAACAGATAC...\n",
      "1    ATGCACAATCAGGAAGAGTGGCTAGACAAGGACAAAACTTTGGTGA...\n",
      "2    ATGGGAGCTGGCACTCTTTTAAATGGATTAGAAAAGGAAAACTTTC...\n",
      "3    ATGAATCAAGGTTACACACAGCTTTCCGCACCGGAACTGAAGGAGA...\n",
      "4    ATGCTTTTCGCTAGATTAGTGCTGCTGTTGGTGTATTTGGCACCAG...\n",
      "5    ATGGATTGCCCCTCAAACGTTGTGTTATTGTTGCTGCAATTAGTTT...\n",
      "6    ATGAACATTAAGACTTTGTGTCATCCAGAATATAAAAGAATCTCCG...\n",
      "7    ATGAGTTTCCTAAGCATTTTTACTTTTTTCAGCGTCCTTATTTCTG...\n",
      "8    ATGTACGAGTACTGCTCAGTTGTAATAAAGAAATACTCCAAGTATA...\n",
      "9    ATGGTGACTGGTGAAGAAAATGTGTATCTAAAGTCAAGCTTATCCA...\n",
      "Name: Sequence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "genomeFile=\"./Data/s288c.fasta\"\n",
    "print(len(seqList))\n",
    "print(seqList[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fd80a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected id Type: locus_tag\n",
      "There are 0 entries NOT found out of 5990\n",
      "5990 distinct record in 5990 entries\n"
     ]
    }
   ],
   "source": [
    "sentenceList=process(list(seqList),genomeFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126109d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740\n",
      "['2 2 1 1 2 1 1 2 3 2 1 2 1 4 1 1 3 2 5 3 2 1 1 2 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 3 6 4 2 1 1 2 2 2 2 2 2 1 1 1 1 3 1 2 2 1 3 1 3 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 2 1']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentenceList))\n",
    "print(sentenceList[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298dceb",
   "metadata": {},
   "source": [
    "We now have the intermediate sentence structure composed of characters including all codon rnaks, this can also be used for training the model and tokenizer, but we will apply one more operation on this file, composing single codon ranks into words of size k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbce831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLineToWords(line,n):\n",
    "    line= line.replace(' ','')\n",
    "    wordList=[]\n",
    "    for i in range(0,len(line)-n,n):\n",
    "        wordList.append(line[i:i+n])\n",
    "    sentence=\" \".join(wordList)\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"expressionPrediction_S288C.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231f6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=4 #k specifies the wordsize, aka number of codon ranks in a word, or understood as size of codon windows\n",
    "wordSentenceList=[]\n",
    "for sentence in sentenceList:\n",
    "    wordSentence=convertLineToWords(sentence,k)\n",
    "    wordSentenceList.append(wordSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1056c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740\n",
      "['2211 2112 3212 1411 3253 2112 1111 1211 1221 1113 6421 1222 2221 1113 1221 3131 1112 1211 2111', '1322 2111 4211 1112 2211 1212 2112 1621 1511 2212 2242 2211 4311 2224 1141 4621 1112 2221 1116 5122 2122 1133 1112 2112 1151 1121 3122 1211 1331 1113 1111 2112 1111 1212 2111 1121 1321 4121 1142 1121 1212 4111 1251 2111 1134 2511 1124 5115 1411 1211 1321 2214']\n"
     ]
    }
   ],
   "source": [
    "print(len(wordSentenceList))\n",
    "print(wordSentenceList[:2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39db9694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2740\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "2735    1\n",
      "2736    1\n",
      "2737    1\n",
      "2738    1\n",
      "2739    1\n",
      "Name: Label, Length: 2740, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labelList=df[\"Label\"]\n",
    "print(len(labelList))\n",
    "print(labelList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b956d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"WordSentence\"]=wordSentenceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c963728d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f2efca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub=df[[\"WordSentence\",\"Label\"]].copy()\n",
    "df_sub=df_sub.rename(columns={\"WordSentence\": \"text\", \"Label\": \"label\"})\n",
    "df_sub.to_csv(\"expressionPrediction_S288C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dd0b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6ff1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb0d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
