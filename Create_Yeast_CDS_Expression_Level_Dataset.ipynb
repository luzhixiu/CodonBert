{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e858ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9476b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24a2199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 GeneName                                           Sequence  \\\n",
      "0           0  YAL067C  ATGTATTCAATTGTTAAAGAGATTATTGTAGATCCTTACAAAAGAC...   \n",
      "1           1  YAL062W  ATGACAAGCGAACCAGAGTTTCAGCAGGCTTACGATGAGATCGTTT...   \n",
      "2           2  YAL061W  ATGAGAGCCTTAGCGTATTTCGGTAAAGGTAACATCAGATTCACCA...   \n",
      "\n",
      "          EXP  Label  \n",
      "0  207.761417      0  \n",
      "1  257.287421      0  \n",
      "2  712.980404      0  \n"
     ]
    }
   ],
   "source": [
    "inputFile=\"./S288C_Expression/EmpiricalExp/Full_S288C.datatable.csv\"\n",
    "df=pd.read_csv(inputFile)\n",
    "print(df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd973c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af03202c",
   "metadata": {},
   "source": [
    "After loading the data, the next step is to convert the raw coding sequences to text sentences compsed of codon usage ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bb4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac75ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, './CUB_Code')\n",
    "import CodonLibraries as CL\n",
    "\n",
    "seqList=df[\"Sequence\"]\n",
    "sentenceList=[]\n",
    "for seq in seqList:\n",
    "    codonList = CL.loadSequence(seq)\n",
    "    sentence=\"\"\n",
    "    for codon in codonList:\n",
    "        sentence+=codon+\" \"\n",
    "    sentenceList.append(sentence[:-1])#this removes the extra redundant space in the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea9956",
   "metadata": {},
   "source": [
    "Now we have converted the sequence to codonLists, then concated them into string sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad09bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAT TCA ATT GTT AAA GAG ATT ATT GTA GAT CCT TAC AAA AGA CTA AAA TGG GGT TTT ATT CCA GTA AAG CGG CAG GTG GAA GAC CTG CCA GAT GAC TTA AAT TCA ACA GAA ATT GTC ACT ATC TCC AAC AGT ATC CAG AGT CAT GAA ACA GCT GAA AAT TTC ATC ACG ACT ACA AGT GAA AAA GAT CAA CTA CAT TTT GAG ACT AGT AGC TAT AGT GAA CAT AAA GAC AAT GTG AAC GTT ACT AGA AGT TAT GAA TAT AGA GAT GAA GCC GAT AGG CCA TGG TGG AGA TTT TTC GAT GAA CAA GAG TAT CGG ATC AAT GAA AAG GAA AGA TCT CAC AAT AAA TGG TAT AGT TGG TTC AAA CAG GGT ACC TCT TTC AAA GAA AAA AAA TTA TTA ATT AAA TTG GAT GTC CTT TTA GCC TTT TAT TCT TGT ATT GCT TAT TGG GTG AAA TAT CTG GAT ACG GTT AAT ATA AAC AAC GCT TAC GTT TCG GGA ATG AAG GAA GAT TTA GGC TTT CAA GGT AAT GAT TTG GTG CAT ACT CAA GTA ATG TAC ACA GTT GGT AAT ATT ATA TTT CAA TTG CCA TTT TTG ATT TAC CTG AAC AAG CTC CCA TTA AAC TAT GTT TTA CCA AGC CTC GAC TTA TGT TGG TCG CTT TTA ACC GTT GGT GCT GCA TAT GTC AAT TCT GTA CCA CAC TTG AAA GCA ATT AGG TTT TTC ATT GGG GCT TTT GAA GCG CCA AGT TAT TTG GCA TAC CAA TAT TTG TTT GGT TCC TTT TAC AAA CAT GAT GAA ATG GTG CGT CGT TCT GCT TTT TAC TAT TTG GGC CAG TAT ATC GGT ATT CTA TCC GCT GGT GGG ATC CAG TCA GCC GTA TAT TCA TCG TTA AAT GGT GTA AAT GGT TTA GAG GGA TGG AGA TGG AAC TTT ATT ATT GAC GCT ATT GTG TCT GTC GTA GTG GGC CTT ATT GGA TTT TAC TCC CTG CCA GGT GAC CCA TAC AAC TGT TAT TCT ATT TTC TTA ACT GAT GAT GAA ATT AGG TTG GCG AGG AAA AGA TTA AAA GAA AAC CAA ACA GGT AAA AGT GAT TTT GAA ACA AAA GTA TTC GAT ATT AAA CTG TGG AAA ACA ATT TTC AGT GAT TGG AAA ATA TAC ATT TTA ACT TTA TGG AAT ATT TTC TGT TGG AAT GAC AGT AAT GTT TCA TCT GGG GCA TAC CTA CTA TGG TTG AAA TCT TTG AAA AGA TAC TCT ATT CCT AAG CTC AAT CAG TTA TCC ATG ATT ACT CCG GGT TTA GGT ATG GTT TAT TTG ATG CTT ACT GGT ATT ATT GCA GAT AAA TTA CAC TCT CGT TGG TTT GCG ATT ATT TTT ACT CAG GTT TTC AAT ATC ATT GGT AAC TCC ATA TTA GCC GCT TGG GAC GTC GCA GAA GGA GCC AAA TGG TTT GCA TTT ATG CTG CAA TGT TTT GGT TGG GCT ATG GCT CCT GTT TTA TAC TCT TGG CAA AAC GAT ATT TGT CGC CGA GAT GCT CAA ACT AGA GCT ATT ACT TTA GTT ACA ATG AAT ATT ATG GCT CAA TCA TCT ACC GCA TGG ATA AGT GTT TTG GTT TGG AAA ACA GAA GAA GCT CCC AGG TAT TTA AAG GGG TTT ACT TTC ACT GCA TGT TCT GCT TTT TGT CTC TCC ATT TGG ACT TTT GTT GTA CTC TAC TTC TAT AAA CGT GAT GAA AGG AAC AAT GCC AAG AAG AAC GGT ATT GTG CTT TAT AAC TCT AAA CAT GGT GTG GAA AAG CCA ACG TCA AAA GAC GTT GAA ACC TTA TCA GTA TCT GAT GAA AAA']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceList[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939a3a9",
   "metadata": {},
   "source": [
    "The next step is to get the genome wide codon usage and generate codon ranks, which will used to replace the codon strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c67da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findSequenceById as FSBID\n",
    "from CAI import RSCU\n",
    "import scipy.stats as ss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process(seqList,genomeFile,tag=\"\"):\n",
    "    geneDict=FSBID.findSequenceByID(genomeFile)\n",
    "    keyList=[]\n",
    "    rscu=RSCU(seqList)\n",
    "    rscu_rank=convertRSCUtoRanks(rscu)\n",
    "    sentenceList = []\n",
    "    for seq in seqList:\n",
    "        codonList=CL.loadSequence(seq)\n",
    "        #remove the first and last five codons:\n",
    "        codonList = codonList[5:]\n",
    "        codonList = codonList[:-5]\n",
    "        try:\n",
    "            codonRankList=[rscu_rank[codon] for codon in codonList]\n",
    "            sentence=\"\"\n",
    "            for rank in codonRankList:\n",
    "                sentence+=str(rank)+\" \"\n",
    "            sentenceList.append(sentence[:-1])\n",
    "        except :\n",
    "            print(\"one error on \",seq)\n",
    "    \n",
    "    return sentenceList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convertRSCUtoRanks(rscu):\n",
    "    synonymousCodons = {\n",
    "        'CYS': ['TGT', 'TGC'],\n",
    "        'ASP': ['GAT', 'GAC'],\n",
    "        'SER': ['TCT', 'TCG', 'TCA', 'TCC', 'AGC', 'AGT'],\n",
    "        'GLN': ['CAA', 'CAG'],\n",
    "        'MET': ['ATG'],\n",
    "        'ASN': ['AAC', 'AAT'],\n",
    "        'PRO': ['CCT', 'CCG', 'CCA', 'CCC'],\n",
    "        'LYS': ['AAG', 'AAA'],\n",
    "        'THR': ['ACC', 'ACA', 'ACG', 'ACT'],\n",
    "        'PHE': ['TTT', 'TTC'],\n",
    "        'ALA': ['GCA', 'GCC', 'GCG', 'GCT'],\n",
    "        'GLY': ['GGT', 'GGG', 'GGA', 'GGC'],\n",
    "        'ILE': ['ATC', 'ATA', 'ATT'],\n",
    "        'LEU': ['TTA', 'TTG', 'CTC', 'CTT', 'CTG', 'CTA'],\n",
    "        'HIS': ['CAT', 'CAC'],\n",
    "        'ARG': ['CGA', 'CGC', 'CGG', 'CGT', 'AGG', 'AGA'],\n",
    "        'TRP': ['TGG'],\n",
    "        'VAL': ['GTA', 'GTC', 'GTG', 'GTT'],\n",
    "        'GLU': ['GAG', 'GAA'],\n",
    "        'TYR': ['TAT', 'TAC']}#'CYS': ['TGT', 'TGC']\n",
    "    rscu_rank=dict()\n",
    "    for aa in synonymousCodons:\n",
    "        codonList=synonymousCodons[aa]\n",
    "        rscuList=[rscu[codon] for codon in codonList]\n",
    "        rankList=ss.rankdata([-1*x for x in rscuList])\n",
    "        for codon,rank in zip(codonList,rankList):\n",
    "            rscu_rank[codon]=int(rank)\n",
    "    return rscu_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f52027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568\n",
      "0    ATGTATTCAATTGTTAAAGAGATTATTGTAGATCCTTACAAAAGAC...\n",
      "1    ATGACAAGCGAACCAGAGTTTCAGCAGGCTTACGATGAGATCGTTT...\n",
      "2    ATGAGAGCCTTAGCGTATTTCGGTAAAGGTAACATCAGATTCACCA...\n",
      "3    ATGAGAGCTTTGGCATATTTCAAGAAGGGTGATATTCACTTCACTA...\n",
      "4    ATGTGGGAACAAAGACGACAAAAGGTAGTTTTTTCCTTGACTATAC...\n",
      "5    ATGAAATTTTCTGCGTATTTATGGTGGCTGTTTTTGAATCTAGCGT...\n",
      "6    ATGGAAATTTCCAGTTCACCATGGAACGACGGTGGATACAGCCCCT...\n",
      "7    ATGCCACCACCATCAAGAAGTAGAATAAACAAAACAAGAACATTAG...\n",
      "8    ATGTCGCCCTCTGCCGTACAATCATCAAAACTAGAAGAACAGTCAA...\n",
      "9    ATGATCTTCCTAAACACCTTCGCAAGGTGCCTTTTAACGTGTTTCG...\n",
      "Name: Sequence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "genomeFile=\"./Data/s288c.fasta\"\n",
    "print(len(seqList))\n",
    "print(seqList[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fd80a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected id Type: locus_tag\n",
      "There are 0 entries NOT found out of 5990\n",
      "5990 distinct record in 5990 entries\n"
     ]
    }
   ],
   "source": [
    "sentenceList=process(list(seqList),genomeFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126109d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568\n",
      "['2 1 1 2 1 2 2 1 1 3 1 1 1 1 1 1 2 2 6 2 4 1 2 5 1 1 2 2 1 2 2 1 1 3 1 3 4 2 3 3 2 3 1 1 2 1 1 1 2 3 4 1 2 3 1 1 1 1 3 1 1 2 1 3 5 1 3 1 1 1 2 1 4 2 1 1 1 3 1 1 1 1 1 1 3 1 2 1 1 1 1 1 2 1 1 1 2 1 6 3 1 1 2 1 1 1 2 1 1 1 1 3 1 2 1 2 1 3 1 2 1 1 1 1 2 2 1 1 1 1 3 4 2 3 1 1 1 1 1 1 1 1 4 1 1 5 1 4 1 1 2 2 2 1 2 1 6 2 1 2 1 1 2 3 1 1 1 1 1 1 4 1 1 1 2 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 2 5 2 2 6 1 2 2 1 1 2 1 5 6 2 2 1 1 6 4 2 3 1 1 1 2 1 3 1 1 2 1 2 1 1 2 1 2 1 2 1 4 1 1 1 4 1 3 1 1 2 2 1 1 1 1 1 4 1 2 1 1 1 1 1 4 3 3 1 1 1 2 1 1 3 2 1 3 1 1 3 4 1 1 4 3 2 2 3 2 1 2 6 2 1 1 2 1 1 2 2 2 1 1 1 2 1 1 1 2 1 1 4 1 3 2 4 3 4 1 2 1 2 4 5 1 1 2 1 2 2 1 1 1 1 2 2 1 1 1 1 1 2 1 4 2 1 1 2 1 1 2 1 2 1 1 3 1 1 1 2 1 2 2 1 1 1 5 1 1 2 1 2 3 1 1 1 2 2 1 2 1 2 1 1 1 2 1 1 1 2 3 1 1 2 1 4 2 2 3 3 1 1 1 1 1 1 1 2 1 1 2 2 6 1 2 2 4 1 1 1 4 1 2 1 1 1 1 1 1 4 1 1 1 1 2 1 1 2 2 1 3 1 1 4 1 1 1 1 2 1 2 1 3 1 1 2 4 2 2 3 1 1 2 3 2 1 2 3 1 1 1 2 1 1 5 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 2 1 1 1 5 4 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 3 2 1 2 3 1 1 1 1 1 2 1 1 1 3 2 1 2 2 4 1 1 2 1 2 1 1 1 1 1 6 4 1 1 1 1 1 2 6 2 2 1 1 3 1 1 2 2 1 3 2 2 2 1 1 4 4 1 2 1 1 1 1 4 1 2 1 4 2 1 2 1 1 3 2 2']\n"
     ]
    }
   ],
   "source": [
    "print(len(sentenceList))\n",
    "print(sentenceList[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b0a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3298dceb",
   "metadata": {},
   "source": [
    "We now have the intermediate sentence structure composed of characters including all codon rnaks, this can also be used for training the model and tokenizer, but we will apply one more operation on this file, composing single codon ranks into words of size k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbce831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLineToWords(line,n):\n",
    "    line= line.replace(' ','')\n",
    "    wordList=[]\n",
    "    for i in range(0,len(line)-n,n):\n",
    "        wordList.append(line[i:i+n])\n",
    "    sentence=\" \".join(wordList)\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90d452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231f6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10 #k specifies the wordsize, aka number of codon ranks in a word, or understood as size of codon windows\n",
    "wordSentenceList=[]\n",
    "for sentence in sentenceList:\n",
    "    wordSentence=convertLineToWords(sentence,k)\n",
    "    wordSentenceList.append(wordSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056c22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39db9694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "4563    1\n",
      "4564    1\n",
      "4565    1\n",
      "4566    0\n",
      "4567    0\n",
      "Name: Label, Length: 4568, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labelList=df[\"Label\"]\n",
    "print(len(labelList))\n",
    "print(labelList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b956d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"WordSentence\"]=wordSentenceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c963728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4066\n"
     ]
    }
   ],
   "source": [
    "df[\"SentenceLength\"]=[len(x) for x in df[\"WordSentence\"]]\n",
    "df=df[df['SentenceLength'] <= 1000]\n",
    "df=df[df['SentenceLength'] >= 2]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2efca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub=df[[\"WordSentence\",\"Label\"]].copy()\n",
    "df_sub=df_sub.rename(columns={\"WordSentence\": \"text\", \"Label\": \"label\"})\n",
    "df_sub.to_csv(\"expressionPrediction_S288C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd0b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6ff1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb0d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52042f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44846ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
